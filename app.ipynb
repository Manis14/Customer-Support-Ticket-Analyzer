{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "028259de-c0df-416c-8723-d16d7e8effff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import gradio as gr\n",
    "import joblib\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from dateutil.parser import parse\n",
    "import warnings \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826f8aa-2114-48d9-9a3c-3486035ba37e",
   "metadata": {},
   "source": [
    "# From here, the web UI has started to be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "145268a5-5eba-45d6-bc72-e47c040d6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Entity Extraction ===\n",
    "products = ['smartwatch v2', 'soundwave 300', 'photosnap cam', 'ecobreeze ac',\n",
    "                'robochef blender', 'powermax battery', 'vision led tv',\n",
    "                'protab x1', 'fitrun treadmill', 'ultraclean vacuum']\n",
    "\n",
    "complaints= ['broken', 'not working', 'late', 'error', 'issue', 'defective', 'cracked', 'missing', 'damaged', 'faulty']\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "    \n",
    "def extract_entities(text):\n",
    "    entities = {'products': [], 'dates': [], 'complaints': []}\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    for product in products:\n",
    "        if product in text_lower:\n",
    "            entities['products'].append(product)\n",
    "\n",
    "    for complaint in complaints:\n",
    "        if complaint in text_lower:\n",
    "            entities['complaints'].append(complaint)\n",
    "\n",
    "    date_matches = re.findall(r'\\b(?:\\d{1,2}\\s)?(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*\\b', text_lower)\n",
    "    for date_str in date_matches:\n",
    "        try:\n",
    "            parsed_date = parse(date_str, fuzzy=True, default=pd.Timestamp('2025-01-01'))\n",
    "            entities['dates'].append(parsed_date.strftime('%d-%B-%Y'))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c879bcb1-3ca9-47cd-b253-d968de365fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Analysis Function ===\n",
    "def analyze_ticket(ticket_text):\n",
    "    vectorizer = joblib.load('vectorizer.pkl')\n",
    "    issue_model = joblib.load('issue_model.pkl')\n",
    "    urgency_model = joblib.load('urgency_model.pkl')\n",
    "    le_issue = joblib.load('le_issue.pkl')\n",
    "    le_urgency = joblib.load('le_urgency.pkl')\n",
    "    \n",
    "    text_cleaned = preprocess(ticket_text)\n",
    "    X_input = vectorizer.transform([text_cleaned])\n",
    "\n",
    "   # Predict\n",
    "    issue_pred = issue_model.predict(X_input)\n",
    "    urgency_pred = urgency_model.predict(X_input)\n",
    "\n",
    "    # Decode labels\n",
    "    issue = le_issue.inverse_transform(issue_pred)[0]\n",
    "    urgency = le_urgency.inverse_transform(urgency_pred)[0]\n",
    "\n",
    "    # Extract entities\n",
    "    entities = extract_entities(ticket_text)\n",
    "    \n",
    "    return {\n",
    "        \"Predicted Issue Type\": issue,\n",
    "        \"Predicted Urgency Level\": urgency,\n",
    "        \"Extracted Entities\": entities\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "599dae5b-9e09-41a1-99e7-e65580ed29fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Predicted Issue Type\": \"Late Delivery\",\n",
      "  \"Predicted Urgency Level\": \"High\",\n",
      "  \"Extracted Entities\": {\n",
      "    \"products\": [\n",
      "      \"robochef blender\"\n",
      "    ],\n",
      "    \"dates\": [\n",
      "      \"13-April-2025\"\n",
      "    ],\n",
      "    \"complaints\": [\n",
      "      \"late\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === 10. Test Example ===\n",
    "ticket = \"Order #53356 for RoboChef Blender is 18 days late. Ordered on 13 April.\"\n",
    "result = analyze_ticket(ticket)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d81b684-01a5-446b-a362-3ea69153f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Gradio Interface ===\n",
    "def gradio_interface(ticket_text):\n",
    "    result = analyze_ticket(ticket_text)\n",
    "    print(result)\n",
    "    return json.dumps(result, indent=2)\n",
    "    \n",
    "iface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(lines=5, placeholder=\"Enter customer ticket text here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Customer Support Ticket Analyzer\",\n",
    "    description=\"Predict issue type, urgency level, and extract entities from support tickets.\"\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313dee3a-d236-4ead-a12c-c15a4e21f765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c80fdb-a82c-42d9-9b5a-58fd26babd10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
